{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f45cd22f-fbf6-4e82-a363-9ff24d1fb246",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ['google_api_key']=\"AIzaSyDBR2GmpbNB3fNtHytmfAklg5QIvAlHigc\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d51c8c4b-81b9-4c19-914f-40d6a3d7f05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\kiit\\anaconda3\\lib\\site-packages (0.1.20)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from langchain) (0.6.6)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.38 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from langchain) (0.0.38)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from langchain) (0.1.52)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from langchain) (0.1.57)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain) (2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c10f5687-a377-45bc-b98e-cb98d2a815e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import GooglePalm\n",
    "api_key=\"AIzaSyDBR2GmpbNB3fNtHytmfAklg5QIvAlHigc\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##creative model maybe output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76867fab-19db-4404-8add-38a45666935e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**La Bella Vita**\n"
     ]
    }
   ],
   "source": [
    "llm = GooglePalm(google_api_key=api_key,temperature=0.6)\n",
    "name = llm(\"I want to open a restaurant for Italian food. Suggest a fancy name for this.\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db1953d-5140-4bc0-8bf5-a6af6270e9be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2435efa-8486-4dde-9f84-3145282fd212",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbc5cfec-21f9-4664-b91a-6c5466e66bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to open a restuarant for Italian food.Suggest a fency name for this.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template_name=PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open a restuarant for {cuisine} food.Suggest a fency name for this.\"\n",
    "\n",
    "\n",
    "    \n",
    ")\n",
    "prompt_template_name.format(cuisine=\"Italian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "865ac535-6005-475b-bb26-adb74d436a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n",
      "C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'* **El Sombrero**\\n* **La Cantina**\\n* **Tacos Al Pastor**\\n* **Chipotle**\\n* **Casa de Burrito**'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "name_chain=LLMChain(llm=llm,prompt=prompt_template_name)\n",
    "name_chain.run(\"Mexican\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53edf3c1-d618-44af-9fda-4d1ab64938b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt_template_name=PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open a restuarant for {cuisine} food.Suggest a fency name for this.\"\n",
    "\n",
    "\n",
    "    \n",
    ")\n",
    "name_chain=LLMChain(llm=llm,prompt=prompt_template_name)\n",
    "prompt_template_items=PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template=\"\"\"Suggest some menu items for {restaurant_name}.Return it as a comma separated values\"\"\")\n",
    "\n",
    "food_items_chain=LLMChain(llm=llm,prompt=prompt_template_items)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b67b7c47-7452-4877-8d79-5c3440402177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**El Sombrero** Menu\n",
      "\n",
      "* Chips and Salsa, $5.00\n",
      "* Quesadilla, $8.00\n",
      "* Enchiladas, $10.00\n",
      "* Tacos, $3.00 each\n",
      "* Burritos, $6.00\n",
      "* Fajitas, $12.00\n",
      "* Chimichangas, $10.00\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "chain=SimpleSequentialChain(chains=[name_chain,food_items_chain])\n",
    "response=chain.run(\"Mexican\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef98384d-c0cb-464d-9ef0-6247c6ce5b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "template_1 = \"I want to open a restuarant for {cuisine} food.Suggest a fency name for this.\"\n",
    "prompt_1 = ChatPromptTemplate.from_template(template_1)\n",
    "chain_1 = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_1,\n",
    "    output_key=\"restaurant_name\"\n",
    ")\n",
    "\n",
    "template_2 = \"Suggest some menu items for {restaurant_name}.Return it as a comma separated values\"\n",
    "prompt_2 = ChatPromptTemplate.from_template(template_2)\n",
    "chain_2 = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_2,\n",
    "    output_key=\"menu_items\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b5a764e-a4de-4441-96e1-da97f293fb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'Arabic',\n",
       " 'restaurant_name': 'Al-Madina',\n",
       " 'menu_items': '**Al-Madina Menu**\\n\\n* Hummus, Baba Ghanoush, Tabbouleh, Fattoush, Falafel, Shawarma, Kebab, Grilled Chicken, Lamb, Beef, Fish, Vegetarian Platter, Desserts'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "sequen_chain=SequentialChain(\n",
    "    chains=[chain_1,chain_2],\n",
    "    input_variables=['cuisine'],\n",
    "    output_variables=['restaurant_name','menu_items']\n",
    "    \n",
    "\n",
    "    \n",
    ")\n",
    "sequen_chain({'cuisine': 'Arabic'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5848a870-3168-4925-b683-a02049dbd86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia in c:\\users\\kiit\\anaconda3\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from wikipedia) (4.12.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from wikipedia) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.5)\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentType,initialize_agent,load_tools\n",
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed7590ee-0f0c-423d-921e-6d4d6a335e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=load_tools(['wikipedia',\"llm-math\"],llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f458bae-e5e7-470f-bbd8-3ef08907113a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentExecutor(tags=['zero-shot-react-description'], agent=ZeroShotAgent(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'input'], template='Answer the following questions as best you can. You have access to the following tools:\\n\\nwikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\nCalculator: Useful for when you need to answer questions about math.\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [wikipedia, Calculator]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}'), llm=GooglePalm(client=<module 'google.generativeai' from 'C:\\\\Users\\\\KIIT\\\\anaconda3\\\\Lib\\\\site-packages\\\\google\\\\generativeai\\\\__init__.py'>, google_api_key=SecretStr('**********'), temperature=0.6)), output_parser=MRKLOutputParser(), allowed_tools=['wikipedia', 'Calculator']), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'C:\\\\Users\\\\KIIT\\\\anaconda3\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=3, lang='en', load_all_available_meta=False, doc_content_chars_max=4000)), Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=GooglePalm(client=<module 'google.generativeai' from 'C:\\\\Users\\\\KIIT\\\\anaconda3\\\\Lib\\\\site-packages\\\\google\\\\generativeai\\\\__init__.py'>, google_api_key=SecretStr('**********'), temperature=0.6)))>, coroutine=<bound method Chain.arun of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=GooglePalm(client=<module 'google.generativeai' from 'C:\\\\Users\\\\KIIT\\\\anaconda3\\\\Lib\\\\site-packages\\\\google\\\\generativeai\\\\__init__.py'>, google_api_key=SecretStr('**********'), temperature=0.6)))>)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    " agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbrose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05199783-a7be-49d6-b572-d8058ceda4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-search-results in c:\\users\\kiit\\anaconda3\\lib\\site-packages (2.4.2)\n",
      "Requirement already satisfied: requests in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from google-search-results) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from requests->google-search-results) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from requests->google-search-results) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from requests->google-search-results) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from requests->google-search-results) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "!pip install google-search-results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46507729-3cdb-4224-9b72-578eabb96448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to know Elon Musk's birth date to answer this question\n",
      "Action: wikipedia\n",
      "Action Input: Elon Musk\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Elon Musk\n",
      "Summary: Elon Reeve Musk ( EE-lon; born June 28, 1971) is a businessman and investor. He is the founder, chairman, CEO, and CTO of SpaceX; angel investor, CEO, product architect, and former chairman of Tesla, Inc.; owner, executive chairman, and CTO of X Corp.; founder of the Boring Company and xAI; co-founder of Neuralink and OpenAI; and president of the Musk Foundation. He is one of the wealthiest people in the world; as of April 2024, Forbes estimates his net worth to be $178 billion. \n",
      "A member of the wealthy South African Musk family, Musk was born in Pretoria and briefly attended the University of Pretoria before immigrating to Canada at age 18, acquiring citizenship through his Canadian-born mother. Two years later, he matriculated at Queen's University at Kingston in Canada. Musk later transferred to the University of Pennsylvania and received bachelor's degrees in economics and physics. He moved to California in 1995 to attend Stanford University, but dropped out after two days and, with his brother Kimbal, co-founded online city guide software company Zip2. The startup was acquired by Compaq for $307 million in 1999. That same year, Musk co-founded X.com, a direct bank. X.com merged with Confinity in 2000 to form PayPal. In October 2002, eBay acquired PayPal for $1.5 billion. Using $100 million of the money he made from the sale of PayPal, Musk founded SpaceX, a spaceflight services company, in 2002. \n",
      "In 2004, Musk became an early investor in electric vehicle manufacturer Tesla Motors, Inc. (later Tesla, Inc.). He became the company's chairman and product architect, assuming the position of CEO in 2008. In 2006, Musk helped create SolarCity, a solar-energy company that was acquired by Tesla in 2016 and became Tesla Energy. In 2013, he proposed a hyperloop high-speed vactrain transportation system. In 2015, he co-founded OpenAI, a nonprofit artificial intelligence research company. The following year, Musk co-founded Neuralink—a neurotechnology company developing brain–computer interfaces—and the Boring Company, a tunnel construction company. In 2018, the U.S. Securities and Exchange Commission (SEC) sued Musk, alleging that he had falsely announced that he had secured funding for a private takeover of Tesla. To settle the case, Musk stepped down as the chairman of Tesla and paid a $20 million fine. In 2022, he acquired Twitter for $44 billion. He subsequently merged the company into newly created X Corp. and rebranded the service as X the following year. In March 2023, Musk founded xAI, an artificial intelligence company.\n",
      "Musk has expressed views that have made him a polarizing figure. He has been criticized for making unscientific and misleading statements, including COVID-19 misinformation and antisemitic conspiracy theories. His ownership of Twitter has been similarly controversial, being marked by layoffs of large numbers of employees, an increase in hate speech and misinformation and disinformation on the website, and changes to Twitter Blue verification.\n",
      "\n",
      "\n",
      "\n",
      "Page: Acquisition of Twitter by Elon Musk\n",
      "Summary: Business magnate Elon Musk initiated an acquisition of American social media company Twitter, Inc. on April 14, 2022, and concluded it on October 28, 2022. Musk had begun buying shares of the company in January 2022, becoming its largest shareholder by April with a 9.1 percent ownership stake. Twitter invited Musk to join its board of directors, an offer he initially accepted before declining. On April 14, Musk made an unsolicited offer to purchase the company, to which Twitter's board responded with a \"poison pill\" strategy to resist a hostile takeover before unanimously accepting Musk's buyout offer of $44 billion on April 25. Musk stated that he planned to introduce new features to the platform, make its algorithms open-source, combat spambot accounts, and promote free speech.\n",
      "In July, Musk announced his intention to terminate the agreement, asserting that Twitter had breached their agreeme\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mElon Musk was born on June 28, 1971. In 2024, his age will be 53.\n",
      "Final Answer: Elon Musk was born on June 28, 1971 and in 2024, his age will be 53.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Elon Musk was born on June 28, 1971 and in 2024, his age will be 53.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"when was Elon musk born?what is his age right now in 2024?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f8915e5-2712-49b9-8ef5-787243214fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the SerpAPI key as an environment variable\n",
    "serpapi_api_key = \"8323832a92612b4e788f4cba61e371cdb54f8fd07c4f20577e89487a9512120f\"\n",
    "os.environ['SERPAPI_API_KEY'] = serpapi_api_key\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc635b1a-84b5-482d-84ba-9324c938d32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now load the tools with the SerpAPI key\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d8df88c-4454-4433-b040-f8dace2261d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbbb6cd6-6f1a-4648-bb61-fc20017e8ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to search for the gdp of india in 2023\n",
      "Action: Search\n",
      "Action Input: gdp of india in 2023\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'type': 'organic_result', 'title': 'Historical GDP and growth rate of India', 'source': 'Forbes India'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI found the gdp of india in 2023\n",
      "Final Answer: 3.33 trillion\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.33 trillion'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"what is the gdp of india in 2023??\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501ddcf7-462a-4ae3-a2ed-226ca3825475",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62765069-10c5-4c7b-9dbd-86264682a319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**El Sombrero**\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "chain=LLMChain(llm=llm,prompt=prompt_template_name,memory=memory)\n",
    "name=chain.run(\"Mexican\")\n",
    "print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bb217d9-ba22-4210-9383-380d104778fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='Mexican'), AIMessage(content='**El Sombrero**')]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "529c9195-b416-4cb8-9666-bf30e0c09769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Mexican\n",
      "AI: **El Sombrero**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement memory (from versions: none)\n",
      "ERROR: No matching distribution found for memory\n"
     ]
    }
   ],
   "source": [
    "print(chain.memory.buffer)\n",
    "!pip install memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "035c67ee-ca23-4990-acaf-094cf3292aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "convo=ConversationChain(llm = GooglePalm(temperature=0.7))\n",
    "print(convo.prompt.template)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "094ce450-79e2-478d-b68d-f236145f5ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'West Indies'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"who won the first cricket world cup?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76ce87c5-e0ed-45da-91ba-0292b3fbe953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"what is 5+5?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "837df530-91b0-4a09-83ab-a440ce1603c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clive Lloyd'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"who was the captain of the wining team?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "619d55b0-91af-42c0-a52d-6a549048136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5f29ae4-5034-46d1-acc8-07ef72123a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'West Indies'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory=ConversationBufferWindowMemory(k=0)\n",
    "convo=ConversationChain(llm = GooglePalm(temperature=0.7),\n",
    "memory=memory)\n",
    "\n",
    "\n",
    "convo.run(\"who won the first cricket world cup? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8fe7a84-425d-470f-a226-f0ade6e215a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"What is the 5+5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d12c21fb-1a25-4c3f-af3a-264e2eb1bd5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aaron Rodgers'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"who was the captain of the winning team?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47174d2-6c56-4670-bfc7-e1d9387970a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
